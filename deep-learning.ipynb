{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras import layers, regularizers, models\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "# sets up the random seed for reproduceability following guide here: https://wandb.ai/sauravmaheshkar/RSNA-MICCAI/reports/How-to-Set-Random-Seeds-in-PyTorch-and-Tensorflow--VmlldzoxMDA2MDQy\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  tf.random.set_seed(seed)\n",
    "  tf.experimental.numpy.random.seed(seed)\n",
    "  tf.random.set_seed(seed)\n",
    "  \n",
    "  print(f\"Random seed set as {seed}\")\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved datasets\n",
    "\n",
    "# 32x32x3\n",
    "#train_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_32x32x3/train')\n",
    "#val_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_32x32x3/validation')\n",
    "#test_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_32x32x3/test')\n",
    "\n",
    "\n",
    "# 96x96x3\n",
    "#train_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3/train')\n",
    "#val_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3/validation')\n",
    "#test_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3/test')\n",
    "\n",
    "# 96x96x3 batch 64\n",
    "train_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch64/train')\n",
    "val_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch64/validation')\n",
    "test_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch64/test')\n",
    "\n",
    "# 96x96x3 batch 128\n",
    "#train_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch128/train')\n",
    "#val_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch128/validation')\n",
    "#test_dataset = tf.data.Dataset.load('Data_TF_saved_cnn_96x96x3_batch128/test')\n",
    "\n",
    "\n",
    "final_train_dataset = train_dataset.concatenate(val_dataset)\n",
    "final_eval_dataset = final_train_dataset.shuffle(buffer_size=10000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "num_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"vertical\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "    #layers.RandomContrast(0.4),\n",
    "    layers.RandomTranslation(0.10, 0.10),\n",
    "    layers.RandomBrightness(0.1, value_range=(0, 1))\n",
    "])\n",
    "\n",
    "batch_images, batch_labels = next(iter(train_dataset))\n",
    "original_image = batch_images[4]\n",
    "\n",
    "\n",
    "original_image_np = original_image.numpy()\n",
    "\n",
    "augmented_image = data_augmentation(tf.expand_dims(original_image, 0), training=True)\n",
    "augmented_image_np = augmented_image[0].numpy()\n",
    "print(augmented_image_np)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "\n",
    "axes[0].imshow(original_image_np)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(augmented_image_np)\n",
    "axes[1].set_title(\"Augmented\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "    0: 2.985006247396918,\n",
    "    1: 0.7715577564861664,\n",
    "    2: 0.9802366135539903,\n",
    "    3: 2.4611950549450547,\n",
    "    4: 2.748609779482263,\n",
    "    5: 10.721017202692595,\n",
    "    6: 1.1288391872735863,\n",
    "    7: 1.5947930574098799,\n",
    "    8: 3.340480074574691,\n",
    "    9: 0.19894241578881625,\n",
    "    10: 0.5672338741590819,\n",
    "    11: 0.6494495038738616,\n",
    "    12: 4.079112122936825,\n",
    "    13: 10.137199434229137\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resNet-9 like model\n",
    "\n",
    "def residual_block(inputs, filters, stride=1, weight_decay=0.0001, dropout_rate=0.4):\n",
    "    x = layers.Conv2D(filters, kernel_size=3, strides=stride, padding='same', use_bias=False, kernel_regularizer=None)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False, kernel_regularizer=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    #x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    #projection\n",
    "    if stride != 1 or inputs.shape[-1] != filters:\n",
    "        skip = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same', kernel_regularizer=None)(inputs)\n",
    "        skip = layers.BatchNormalization()(skip)\n",
    "    else:\n",
    "        skip = inputs\n",
    "    \n",
    "    x = layers.Add()([x, skip])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def create_resnet_v1(weight_decay=0.0001, dropout_rate=0.4):\n",
    "    #input shape\n",
    "    input_shape = (96, 96, 3)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    #augmentation\n",
    "    x = data_augmentation(inputs, training=True)\n",
    "    \n",
    "    #initial conv layer\n",
    "    x = layers.Conv2D(64, strides=2, kernel_size=7, padding='same', kernel_regularizer=None)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    \n",
    "    # res stage 1\n",
    "    x = residual_block(x, 64, stride=1, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "    x = residual_block(x, 64, stride=1, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "\n",
    "    \n",
    "    # res stage 2\n",
    "    x = residual_block(x, 128, stride=2, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "    x = residual_block(x, 128, stride=1, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "\n",
    "    \n",
    "    # res stage 3\n",
    "    x = residual_block(x, 256, stride=2, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "    x = residual_block(x, 256, stride=1, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "\n",
    "    \n",
    "    # res stage 4\n",
    "    x = residual_block(x, 512, stride=2, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "    x = residual_block(x, 512, stride=1, weight_decay=weight_decay, dropout_rate=dropout_rate)\n",
    "  \n",
    "    # avg pooling instead of flatten (apparently more used?)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', kernel_regularizer=None)(x)\n",
    "    \n",
    "    # group and return model\n",
    "    model = tf.keras.Model(inputs, outputs)   \n",
    "    return model \n",
    "\n",
    "model = create_resnet_v1(weight_decay=0.0001, dropout_rate=0.5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AML LOCAL exam 2024\\wandb\\run-20250131_083734-zmmvg73p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test/runs/zmmvg73p' target=\"_blank\">big aug3</a></strong> to <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test/runs/zmmvg73p' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test/runs/zmmvg73p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "Epoch 1/20\n",
      "506/506 [==============================] - 19s 36ms/step - loss: 2.0871 - accuracy: 0.3782\n",
      "Epoch 2/20\n",
      "506/506 [==============================] - 18s 35ms/step - loss: 1.6425 - accuracy: 0.4614\n",
      "Epoch 3/20\n",
      "506/506 [==============================] - 18s 35ms/step - loss: 1.5131 - accuracy: 0.4871\n",
      "Epoch 4/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 1.3697 - accuracy: 0.5310\n",
      "Epoch 5/20\n",
      "506/506 [==============================] - 17s 33ms/step - loss: 1.2623 - accuracy: 0.5621\n",
      "Epoch 6/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 1.1857 - accuracy: 0.5881\n",
      "Epoch 7/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 1.0960 - accuracy: 0.6173\n",
      "Epoch 8/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 1.0199 - accuracy: 0.6435\n",
      "Epoch 9/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.9541 - accuracy: 0.6645\n",
      "Epoch 10/20\n",
      "506/506 [==============================] - 18s 35ms/step - loss: 0.8982 - accuracy: 0.6815\n",
      "Epoch 11/20\n",
      "506/506 [==============================] - 18s 35ms/step - loss: 0.8570 - accuracy: 0.6954\n",
      "Epoch 12/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.8176 - accuracy: 0.7091\n",
      "Epoch 13/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.7696 - accuracy: 0.7267\n",
      "Epoch 14/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.7424 - accuracy: 0.7354\n",
      "Epoch 15/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.6954 - accuracy: 0.7507\n",
      "Epoch 16/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.6703 - accuracy: 0.7571\n",
      "Epoch 17/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.6452 - accuracy: 0.7641\n",
      "Epoch 18/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.6243 - accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "506/506 [==============================] - 17s 34ms/step - loss: 0.5911 - accuracy: 0.7833\n",
      "Epoch 20/20\n",
      "506/506 [==============================] - 17s 33ms/step - loss: 0.5670 - accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.79096</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">big aug3</strong> at: <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test/runs/zmmvg73p' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test/runs/zmmvg73p</a><br/> View project at: <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/CNN-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250131_083734-zmmvg73p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Initialize W&B\n",
    "\n",
    "wandb.init(\n",
    "    project=\"CNN-test\", \n",
    "    name=\"big aug3\", \n",
    "    group=\"aug\", \n",
    "    config={\n",
    "        \"seet\": 42,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"epochs\": 20,\n",
    "        \"batch_size\": 64,\n",
    "        \"dropout\": 0.4,\n",
    "        \"image_size\": 96,\n",
    "        \"batch_normalization\": True,\n",
    "        \"flip\": \"vertical\",\n",
    "        \"rotation\": 0.05,\n",
    "        \"zoom\": 0.1,\n",
    "        \"translation\": (0.10, 0.10),\n",
    "        \"brightness\": 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2) Create the ResNet model\n",
    "model = create_resnet_v1()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.99),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\"\"\"early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")\"\"\"\n",
    "\n",
    "history = model.fit(\n",
    "    final_train_dataset,\n",
    "    #validation_data=val_dataset,\n",
    "    #class_weight=class_weights,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[WandbMetricsLogger()]#, early_stopping]\n",
    ")\n",
    "\n",
    "#best_val_loss = min(history.history['val_loss'])\n",
    "#wandb.log({\"best_val_loss\": best_val_loss})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5) Finish the W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWEEP FOR LR AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'name': 'ResNet_optimizer_sweep3',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'optimizer_config': {\n",
    "            'values': [\n",
    "                {'optimizer': 'SGD', 'momentum': 0.9},\n",
    "                {'optimizer': 'SGD', 'momentum': 0.95},\n",
    "                {'optimizer': 'SGD', 'momentum': 0.99},\n",
    "                {'optimizer': 'Adam', 'momentum': 0.0}\n",
    "            ]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.000100, 0.000250, 0.000500, 0.001000, 0.002500, 0.005000, 0.010000, 0.025000]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 40\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'value': 64\n",
    "        },\n",
    "        'image_size': {\n",
    "            'value': 96\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"CNN-test\")\n",
    "\n",
    "def train():\n",
    "    wandb.init()\n",
    "    \n",
    "    model = create_resnet_v1()\n",
    "    \n",
    "    optimizer_config = wandb.config.optimizer_config\n",
    "\n",
    "    if optimizer_config['optimizer'] == 'Adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=wandb.config.learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(\n",
    "            learning_rate=wandb.config.learning_rate,\n",
    "            momentum=optimizer_config['momentum']\n",
    "        )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=wandb.config.epochs,\n",
    "        batch_size=wandb.config.batch_size,\n",
    "        callbacks=[WandbMetricsLogger(), early_stopping]\n",
    "    )\n",
    "    \n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "    wandb.log({\"best_val_loss\": best_val_loss})\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "\n",
    "wandb.agent(sweep_id, train, count=640)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawacherfuglsang\u001b[0m (\u001b[33mawacherfuglsang-university-of-southern-denmark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AML LOCAL exam 2024\\wandb\\run-20250131_075012-3148ycx6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval/runs/3148ycx6' target=\"_blank\">resnet50_final_eval</a></strong> to <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval/runs/3148ycx6' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval/runs/3148ycx6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/final_eval/runs/3148ycx6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1cbda185d50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"final_eval\",\n",
    "    name=\"resnet50_final_eval\",\n",
    "    config={\n",
    "        \"epochs_phase1\": 3,\n",
    "        \"epochs_phase2\": 3,\n",
    "        \"learning_rate_phase1\": 1e-3,\n",
    "        \"learning_rate_phase2\": 1e-5,\n",
    "        \"unfreeze_layers\": 20\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and 'unnormalize' image\n",
    "def resize_to_224(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image * 255.0\n",
    "    return image, label\n",
    "\n",
    "# Apply the resizing transformation\n",
    "train_dataset = train_dataset.map(resize_to_224, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.map(resize_to_224, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset  = test_dataset.map(resize_to_224, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "final_train_dataset = train_dataset.concatenate(val_dataset)\n",
    "\n",
    "# Optionally, for performance, prefetch batches\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset   = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset  = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#for final eval\n",
    "final_eval_dataset = final_train_dataset.shuffle(buffer_size=10000).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 224, 224, 3)\n",
      "Min pixel value: 0.0\n",
      "Max pixel value: 255.0\n"
     ]
    }
   ],
   "source": [
    "# Get one batch from the dataset\n",
    "sample_batch = next(iter(final_train_dataset))\n",
    "\n",
    "# Extract one image and label\n",
    "sample_image, sample_label = sample_batch\n",
    "\n",
    "# Print the shape and pixel range\n",
    "print(\"Image shape:\", sample_image.shape)\n",
    "print(\"Min pixel value:\", tf.reduce_min(sample_image).numpy())\n",
    "print(\"Max pixel value:\", tf.reduce_max(sample_image).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                28686     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,616,398\n",
      "Trainable params: 28,686\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 14\n",
    "\n",
    "# Load the base ResNet50 model\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "506/506 [==============================] - 66s 113ms/step - loss: 0.8985 - accuracy: 0.6914\n",
      "Epoch 2/3\n",
      "506/506 [==============================] - 57s 112ms/step - loss: 0.6714 - accuracy: 0.7600\n",
      "Epoch 3/3\n",
      "506/506 [==============================] - 57s 113ms/step - loss: 0.6077 - accuracy: 0.7813\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    final_train_dataset,\n",
    "    epochs=3,\n",
    "    #validation_data=val_dataset,\n",
    "    #class_weight=class_weights,\n",
    "    callbacks=[WandbMetricsLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model summary (partially unfrozen) ===\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                28686     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,616,398\n",
      "Trainable params: 8,960,014\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "506/506 [==============================] - 65s 122ms/step - loss: 0.5223 - accuracy: 0.8129\n",
      "Epoch 2/3\n",
      "506/506 [==============================] - 61s 121ms/step - loss: 0.4374 - accuracy: 0.8441\n",
      "Epoch 3/3\n",
      "506/506 [==============================] - 61s 121ms/step - loss: 0.3611 - accuracy: 0.8747\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower LR\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history2 = model.fit(\n",
    "    final_train_dataset,\n",
    "    epochs=3,\n",
    "    #validation_data=val_dataset,\n",
    "    #class_weight=class_weights,\n",
    "    callbacks=[WandbMetricsLogger()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model summary (partially unfrozen) ===\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                28686     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,616,398\n",
      "Trainable params: 23,563,278\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "  6/506 [..............................] - ETA: 2:45 - loss: 0.2927 - accuracy: 0.9010WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1255s vs `on_train_batch_end` time: 0.1709s). Check your callbacks.\n",
      "506/506 [==============================] - 171s 328ms/step - loss: 0.2753 - accuracy: 0.9108\n",
      "Epoch 2/3\n",
      "506/506 [==============================] - 165s 326ms/step - loss: 0.2451 - accuracy: 0.9212\n",
      "Epoch 3/3\n",
      "506/506 [==============================] - 166s 327ms/step - loss: 0.2219 - accuracy: 0.9309\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Recompile with further lower LR\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history3 = model.fit(\n",
    "    final_train_dataset,\n",
    "    epochs=3,\n",
    "    #validation_data=val_dataset,\n",
    "    #class_weight=class_weights,\n",
    "    callbacks=[WandbMetricsLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 7s 114ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46        88\n",
      "           1       0.69      0.77      0.73       333\n",
      "           2       0.54      0.53      0.54       262\n",
      "           3       0.94      0.92      0.93       111\n",
      "           4       0.99      0.90      0.94        99\n",
      "           5       0.42      0.20      0.27        25\n",
      "           6       0.98      0.96      0.97       239\n",
      "           7       0.95      0.98      0.97       170\n",
      "           8       0.99      0.95      0.97        81\n",
      "           9       0.86      0.84      0.85      1288\n",
      "          10       0.61      0.64      0.63       453\n",
      "          11       0.95      0.97      0.96       424\n",
      "          12       0.59      0.38      0.46        64\n",
      "          13       0.78      0.54      0.64        26\n",
      "\n",
      "    accuracy                           0.80      3663\n",
      "   macro avg       0.76      0.72      0.74      3663\n",
      "weighted avg       0.80      0.80      0.80      3663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf raport\n",
    "y_pred_probs = model.predict(test_dataset)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▃▄▅▆▆▇██</td></tr><tr><td>epoch/epoch</td><td>▁▅█▁▅█▁▅█</td></tr><tr><td>epoch/learning_rate</td><td>███▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▄▃▂▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▄▆▆▆▇██</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.91572</td></tr><tr><td>epoch/epoch</td><td>2</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.25523</td></tr><tr><td>epoch/val_accuracy</td><td>0.81046</td></tr><tr><td>epoch/val_loss</td><td>0.57828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet50_fine_tune_example6</strong> at: <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/my_resnet_project/runs/7exfqdle' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/my_resnet_project/runs/7exfqdle</a><br/> View project at: <a href='https://wandb.ai/awacherfuglsang-university-of-southern-denmark/my_resnet_project' target=\"_blank\">https://wandb.ai/awacherfuglsang-university-of-southern-denmark/my_resnet_project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250131_063838-7exfqdle\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image, label in train_dataset.unbatch().take(1):  \n",
    "    image = tf.squeeze(image).numpy()\n",
    "    label = label.numpy()\n",
    "    \n",
    "    #normalize\n",
    "    image = image/255\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Hide axis\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'conv4_block6_out'\n",
    "\n",
    "activation_model = tf.keras.Model(\n",
    "    inputs=base_model.input,\n",
    "    outputs=base_model.get_layer(layer_name).output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataset.unbatch().take(1):\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    label = label.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[ 53.060997,  41.221   ,  33.32    ],\n",
       "         [ 52.63244 ,  40.792442,  33.177147],\n",
       "         [ 51.346718,  39.50672 ,  32.748573],\n",
       "         ...,\n",
       "         [102.91816 ,  90.07816 ,  83.17716 ],\n",
       "         [106.77534 ,  93.93534 ,  87.03434 ],\n",
       "         [108.061   ,  95.221   ,  88.32    ]],\n",
       "\n",
       "        [[ 52.346718,  40.50672 ,  32.748573],\n",
       "         [ 51.95896 ,  40.139366,  32.646523],\n",
       "         [ 50.795708,  39.037346,  32.340416],\n",
       "         ...,\n",
       "         [103.91816 ,  91.07816 ,  84.17716 ],\n",
       "         [107.77534 ,  94.93534 ,  88.03434 ],\n",
       "         [109.061   ,  96.221   ,  89.32    ]],\n",
       "\n",
       "        [[ 50.203865,  38.36387 ,  31.034294],\n",
       "         [ 49.93856 ,  38.1802  ,  31.05471 ],\n",
       "         [ 49.14263 ,  37.629158,  31.115929],\n",
       "         ...,\n",
       "         [106.91816 ,  94.07816 ,  87.17716 ],\n",
       "         [110.77534 ,  97.93534 ,  91.03434 ],\n",
       "         [112.061   ,  99.221   ,  92.32    ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-28.51043 , -39.350426, -45.251427],\n",
       "         [-28.571648, -39.411644, -45.312645],\n",
       "         [-28.755325, -39.59532 , -45.496323],\n",
       "         ...,\n",
       "         [ 62.38752 ,  49.547523,  42.646523],\n",
       "         [ 62.571205,  49.73121 ,  42.830208],\n",
       "         [ 62.632423,  49.792427,  42.891426]],\n",
       "\n",
       "        [[-28.081848, -38.921844, -44.822845],\n",
       "         [-28.2043  , -39.044296, -44.945297],\n",
       "         [-28.571648, -39.411644, -45.312645],\n",
       "         ...,\n",
       "         [ 61.714058,  48.87406 ,  41.97306 ],\n",
       "         [ 62.081398,  49.2414  ,  42.3404  ],\n",
       "         [ 62.203865,  49.36387 ,  42.462868]],\n",
       "\n",
       "        [[-27.939003, -38.779   , -44.68    ],\n",
       "         [-28.081856, -38.921852, -44.822853],\n",
       "         [-28.51043 , -39.350426, -45.251427],\n",
       "         ...,\n",
       "         [ 61.48957 ,  48.649574,  41.748573],\n",
       "         [ 61.918144,  49.078148,  42.177147],\n",
       "         [ 62.060997,  49.221   ,  42.32    ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor = preprocess_input(image)\n",
    "image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of activation maps: (1, 14, 14, 1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activations = activation_model(image_tensor)\n",
    "\n",
    "print(\"Shape of activation maps:\", activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "activation_maps = activations[0]\n",
    "\n",
    "num_channels_to_show = 6\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(0, num_channels_to_show):\n",
    "    ax = plt.subplot(1, num_channels_to_show, i+1)\n",
    "    channel_image = activation_maps[..., i].numpy()\n",
    "\n",
    "    plt.imshow(channel_image)\n",
    "    plt.title(f'Channel {i}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
